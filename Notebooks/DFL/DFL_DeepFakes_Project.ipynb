{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DFL DeepFakes Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IYtWMzOvLQ3s",
        "BDg_jiQ9adQe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cKdTCuv4tXh"
      },
      "source": [
        "# Welcome to DFL-Colab!\n",
        "\n",
        "This is an adapted version of the DFL for Google Colab.\n",
        "\n",
        "\n",
        "# Overview\n",
        "*   Extractor works in full functionality.\n",
        "*   Training can work without preview.\n",
        "*   Merger works in full functionality.\n",
        "*   You can import/export workspace with your Google Drive.\n",
        "*   Import/export and another manipulations with workspace you can do in \"Manage workspace\" block\n",
        "*   Google Colab machine active for 12 hours. DFL-Colab makes a backup of your workspace in training mode.\n",
        "*   Google does not like long-term heavy calculations. Therefore, for training more than two sessions in a row, use two Google accounts. It is recommended to split your training over 2 accounts, but you can use one Google Drive account to store your workspace.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYtWMzOvLQ3s"
      },
      "source": [
        "## Prevent random disconnects\n",
        "\n",
        "This cell runs JS code to automatic reconnect to runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtClEMAMLVHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23fee361-8bca-48e6-991b-e3bb9897d18d"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDg_jiQ9adQe"
      },
      "source": [
        "## Check GPU\n",
        "\n",
        "*   Google Colab can provide you with one of Tesla graphics cards: K80, T4, P4 or P100\n",
        "*   Here you can check the model of GPU before using DeepFaceLab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJe71S6gbzt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34923658-8df5-4f00-c58f-a66523cb86eb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb 17 16:20:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVn21kt40Gw"
      },
      "source": [
        "## Install or update DeepFaceLab\n",
        "\n",
        "* Install or update DeepFAceLab directly from Github\n",
        "* Requirements install is automatically\n",
        "* Automatically sets timer to prevent random disconnects\n",
        "* \"Download FFHQ\" option means to download high quality FFHQ dataset instead of CelebA. FFHQ takes up more memory, so it will take longer to download than CelebA. It is recommended to enable this option if you are doing pretrain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG-f2WqT4fLK",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1501ab0-a487-4e6f-a12c-cc67accdfbf2"
      },
      "source": [
        "#@title Install or update DeepFaceLab from Github\n",
        "\n",
        "Mode = \"install\" #@param [\"install\", \"update\"]\n",
        "Download_FFHQ = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "pretrain_link = \"https://github.com/chervonij/DFL-Colab/releases/download/\"\n",
        "pretrain_link = pretrain_link+\"pretrain_FFHQ/pretrain_FFHQ.zip\" if Download_FFHQ else pretrain_link+\"pretrain-CelebA/pretrain_CelebA.zip\"\n",
        "\n",
        "from pathlib import Path\n",
        "if (Mode == \"install\"):\n",
        "  !git clone https://github.com/iperov/DeepFaceLab.git\n",
        "\n",
        "  # fix linux warning\n",
        "  # /usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"rt\")\n",
        "  data = fin.read()\n",
        "  data = data.replace('if cache:', 'if False:')\n",
        "  fin.close()\n",
        "\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"wt\")\n",
        "  fin.write(data)\n",
        "  fin.close()\n",
        "else:\n",
        "  %cd /content/DeepFaceLab\n",
        "  !git pull\n",
        "\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install -r /content/DeepFaceLab/requirements-colab.txt\n",
        "!pip install --upgrade scikit-image\n",
        "!apt-get install cuda-10-0\n",
        "\n",
        "if not Path(\"/content/pretrain\").exists():\n",
        "  print(\"Downloading Pretrain faceset ... \")\n",
        "  !wget -q --no-check-certificate -r $pretrain_link -O /content/pretrain_faceset.zip\n",
        "  !mkdir /content/pretrain\n",
        "  !unzip -q /content/pretrain_faceset.zip -d /content/pretrain/\n",
        "  !rm /content/pretrain_faceset.zip\n",
        "\n",
        "if not Path(\"/content/pretrain_Q96\").exists():\n",
        "  print(\"Downloading Q96 pretrained model ...\")\n",
        "  !wget -q --no-check-certificate -r 'https://github.com/chervonij/DFL-Colab/releases/download/Q96_model_pretrained/Q96_model_pretrained.zip' -O /content/pretrain_Q96.zip\n",
        "  !mkdir /content/pretrain_Q96\n",
        "  !unzip -q /content/pretrain_Q96.zip -d /content/pretrain_Q96/\n",
        "  !rm /content/pretrain_Q96.zip\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  !mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model  \n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"\\nDone!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepFaceLab'...\n",
            "remote: Enumerating objects: 7193, done.\u001b[K\n",
            "remote: Total 7193 (delta 0), reused 0 (delta 0), pack-reused 7193\u001b[K\n",
            "Receiving objects: 100% (7193/7193), 815.33 MiB | 37.46 MiB/s, done.\n",
            "Resolving deltas: 100% (4641/4641), done.\n",
            "Checking out files: 100% (204/204), done.\n",
            "Uninstalling tensorflow-2.4.1:\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 1)) (4.41.1)\n",
            "Collecting numpy==1.19.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/f7/a7d7e0de99a7b43bd95aaddcf29e65b5a185ca389dd1329a53cc986edc38/numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 220kB/s \n",
            "\u001b[?25hCollecting h5py==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 48.6MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.1.0.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 86kB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.1.17\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/10/330cbc8e63d072d40413f4d470444a6a1e8c8c6a80b2a4ac302d1252ca1b/ffmpeg_python-0.1.17-py3-none-any.whl\n",
            "Collecting scikit-image==0.14.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/06/d560630eb9e36d90d69fe57d9ff762d8f501664ce478b8a0ae132b3c3008/scikit_image-0.14.2-cp36-cp36m-manylinux1_x86_64.whl (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 92kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 7)) (1.4.1)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tensorflow-gpu==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.9.0->-r /content/DeepFaceLab/requirements-colab.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python==0.1.17->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (7.0.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.5)\n",
            "Requirement already satisfied: dask[array]>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.12.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.36.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=1.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (0.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (53.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.25.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (4.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.4.0)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.3.1 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 2.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.3.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, h5py, opencv-python, ffmpeg-python, scikit-image, colorama, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "Successfully installed colorama-0.4.4 ffmpeg-python-0.1.17 h5py-2.9.0 numpy-1.19.3 opencv-python-4.1.0.25 scikit-image-0.14.2 tensorflow-estimator-2.3.0 tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2020.9.3)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.19.3)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-image\n",
            "  Found existing installation: scikit-image 0.14.2\n",
            "    Uninstalling scikit-image-0.14.2:\n",
            "      Successfully uninstalled scikit-image-0.14.2\n",
            "Successfully installed scikit-image-0.17.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 17 not upgraded.\n",
            "Downloading Pretrain faceset ... \n",
            "Downloading Q96 pretrained model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwOlJG4MdLC"
      },
      "source": [
        "## Manage workspace\n",
        "\n",
        "\n",
        "\n",
        "*   You can import/export workspace or individual data, like model files with Google Drive\n",
        "*   Also, you can use HFS (HTTP Fileserver) for directly import/export you workspace from your computer\n",
        "*   You can clear all workspace or delete part of it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4w_sUzgOQmL",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c2e08b-ccfb-4d90-b4c3-7f8ada1ded69"
      },
      "source": [
        "#@title Import from Drive\n",
        "\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"models\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  unzip_cmd=\" -q \"+Archive_name\n",
        "  \n",
        "  %cd $path\n",
        "  copy_cmd = \"/content/drive/My\\ Drive/\"+Archive_name+\" \"+path\n",
        "  !cp $copy_cmd\n",
        "  !unzip $unzip_cmd    \n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "  \n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y3WfuwoNXqC",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4513d5-9ca3-4346-a7e3-5799f70e8a21"
      },
      "source": [
        "#@title Export to Drive { form-width: \"30%\" }\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"merged\", \"merged_mask\", \"models\", \"result video\", \"result_mask video\"]\n",
        "Archive_name = \"final_workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  zip_cmd=\"-r -q \"+Archive_name+\" \"\n",
        "  \n",
        "  %cd $path\n",
        "  zip_cmd+=mode\n",
        "  !zip $zip_cmd\n",
        "  copy_cmd = \" \"+Archive_name+\"  /content/drive/My\\ Drive/\"\n",
        "  !cp $copy_cmd\n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"merged\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged\")\n",
        "elif Mode == \"merged_mask\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged_mask\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "elif Mode == \"result video\":\n",
        "  !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n",
        "  \n",
        "print(\"Done!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hIvJtxwTGcb"
      },
      "source": [
        "#@title Import from URL{ form-width: \"30%\", display-mode: \"form\" }\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"unzip to content\" #@param [\"unzip to content\", \"unzip to content/workspace\", \"unzip to content/workspace/data_src\", \"unzip to content/workspace/data_src/aligned\", \"unzip to content/workspace/data_dst\", \"unzip to content/workspace/data_dst/aligned\", \"unzip to content/workspace/model\", \"download to content/workspace\"]\n",
        "\n",
        "import urllib\n",
        "from pathlib import Path\n",
        "\n",
        "def unzip(zip_path, dest_path):\n",
        "\n",
        "    \n",
        "  unzip_cmd = \" unzip -q \" + zip_path + \" -d \"+dest_path\n",
        "  !$unzip_cmd  \n",
        "  rm_cmd = \"rm \"+dest_path + url_path.name\n",
        "  !$rm_cmd\n",
        "  print(\"Unziped!\")\n",
        "  \n",
        "\n",
        "if Mode == \"unzip to content\":\n",
        "  dest_path = \"/content/\"\n",
        "elif Mode == \"unzip to content/workspace\":\n",
        "  dest_path = \"/content/workspace/\"\n",
        "elif Mode == \"unzip to content/workspace/data_src\":\n",
        "  dest_path = \"/content/workspace/data_src/\"\n",
        "elif Mode == \"unzip to content/workspace/data_src/aligned\":\n",
        "  dest_path = \"/content/workspace/data_src/aligned/\"\n",
        "elif Mode == \"unzip to content/workspace/data_dst\":\n",
        "  dest_path = \"/content/workspace/data_dst/\"\n",
        "elif Mode == \"unzip to content/workspace/data_dst/aligned\":\n",
        "  dest_path = \"/content/workspace/data_dst/aligned/\"\n",
        "elif Mode == \"unzip to content/workspace/model\":\n",
        "  dest_path = \"/content/workspace/model/\"\n",
        "elif Mode == \"download to content/workspace\":\n",
        "  dest_path = \"/content/workspace/\"\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  cmd = \"mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"\n",
        "  !$cmd\n",
        "\n",
        "url_path = Path(URL)\n",
        "urllib.request.urlretrieve ( URL, dest_path + url_path.name )\n",
        "\n",
        "if (url_path.suffix == \".zip\") and (Mode!=\"download to content/workspace\"):\n",
        "  unzip(dest_path + url_path.name, dest_path)\n",
        "\n",
        "  \n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V1sc7rxNKLO",
        "cellView": "form"
      },
      "source": [
        "#@title Export to URL\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"upload workspace\" #@param [\"upload workspace\", \"upload data_src\", \"upload data_dst\", \"upload data_src aligned\", \"upload data_dst aligned\", \"upload merged\", \"upload model\", \"upload result video\"]\n",
        "\n",
        "cmd_zip = \"zip -r -q \"\n",
        "\n",
        "def run_cmd(zip_path, curl_url):\n",
        "  cmd_zip = \"zip -r -q \"+zip_path\n",
        "  cmd_curl = \"curl --silent -F \"+curl_url+\" -D out.txt > /dev/null\"\n",
        "  !$cmd_zip\n",
        "  !$cmd_curl\n",
        "\n",
        "\n",
        "if Mode == \"upload workspace\":\n",
        "  %cd \"/content\"\n",
        "  run_cmd(\"workspace.zip workspace/\",\"'data=@/content/workspace.zip' \"+URL)\n",
        "elif Mode == \"upload data_src\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src.zip data_src/\", \"'data=@/content/workspace/data_src.zip' \"+URL)\n",
        "elif Mode == \"upload data_dst\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst.zip data_dst/\", \"'data=@/content/workspace/data_dst.zip' \"+URL)\n",
        "elif Mode == \"upload data_src aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src_aligned.zip data_src/aligned\", \"'data=@/content/workspace/data_src_aligned.zip' \"+URL )\n",
        "elif Mode == \"upload data_dst aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst_aligned.zip data_dst/aligned/\", \"'data=@/content/workspace/data_dst_aligned.zip' \"+URL)\n",
        "elif Mode == \"upload merged\":\n",
        "  %cd \"/content/workspace/data_dst\"\n",
        "  run_cmd(\"merged.zip merged/\",\"'data=@/content/workspace/data_dst/merged.zip' \"+URL )\n",
        "elif Mode == \"upload model\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"model.zip model/\", \"'data=@/content/workspace/model.zip' \"+URL)\n",
        "elif Mode == \"upload result video\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"result.zip result.mp4\", \"'data=@/content/workspace/result.zip' \"+URL)\n",
        "  \n",
        "  \n",
        "!rm *.zip\n",
        "\n",
        "%cd \"/content\"\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta6ue_UGMkki",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42150cc7-27ea-4251-d5a4-7be8d007ee35"
      },
      "source": [
        "#@title Delete and recreate\n",
        "Mode = \"Delete and recreate workspace\" #@param [\"Delete and recreate workspace\", \"Delete models\", \"Delete data_src\", \"Delete data_src aligned\", \"Delete data_src video\", \"Delete data_dst\", \"Delete data_dst aligned\", \"Delete merged frames\"]\n",
        "\n",
        "%cd \"/content\" \n",
        "\n",
        "if Mode == \"Delete and recreate workspace\":\n",
        "  cmd = \"rm -r /content/workspace ; mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"  \n",
        "elif Mode == \"Delete models\":\n",
        "  cmd = \"rm -r /content/workspace/model/*\"\n",
        "elif Mode == \"Delete data_src\":\n",
        "  cmd = \"rm /content/workspace/data_src/*.png || rm -r /content/workspace/data_src/*.jpg\"\n",
        "elif Mode == \"Delete data_src aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_src/aligned/*\"\n",
        "elif Mode == \"Delete data_src video\":\n",
        "  cmd = \"rm -r /content/workspace/data_src.*\"\n",
        "elif Mode == \"Delete data_dst\":\n",
        "  cmd = \"rm /content/workspace/data_dst/*.png || rm /content/workspace/data_dst/*.jpg\"\n",
        "elif Mode == \"Delete data_dst aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/aligned/*\"\n",
        "elif Mode == \"Delete merged frames\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/merged; rm -r /content/workspace/data_dst/merged_mask\"\n",
        "  \n",
        "!$cmd\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUNVcbujhm00"
      },
      "source": [
        "## Extract, sorting and faceset tools\n",
        "* Extract frames for SRC or DST video.\n",
        "* Denoise SRC or DST video. \"Factor\" param set intesity of denoising\n",
        "* Detect and align faces. If you need, you can get frames with debug landmarks.\n",
        "* Export workspace to Google Drive after extract and sort it manually (In \"Manage Workspace\" block)\n",
        "* You can enhance your facesets with DFL FacesetEnhancer.\n",
        "* Apply or remove trained XSeg model to the extracted faces\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwJEbz5Nhot0",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614aacf0-ad67-4f77-fca1-03e0d6a24b7d"
      },
      "source": [
        "#@title Extract frames\n",
        "Video = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed extract-video\"\n",
        "\n",
        "if Video == \"data_dst\":\n",
        "  cmd+= \" --input-file workspace/data_dst.* --output-dir workspace/data_dst/\"\n",
        "else:\n",
        "  cmd+= \" --input-file workspace/data_src.* --output-dir workspace/data_src/\"\n",
        "  \n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "[0] Enter FPS ( ?:help ) : \n",
            "0\n",
            "[png] Output image format ( png/jpg ?:help ) : \n",
            "png\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/workspace/data_dst.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41avc1\n",
            "    creation_time   : 2021-02-02T17:48:00.000000Z\n",
            "    playback_requirements: QuickTime 6.0 or greater\n",
            "    playback_requirements-eng: QuickTime 6.0 or greater\n",
            "    encoder         : vlc 3.0.8 stream output\n",
            "    encoder-eng     : vlc 3.0.8 stream output\n",
            "  Duration: 00:01:08.04, start: 0.000000, bitrate: 458 kb/s\n",
            "    Stream #0:0(eng): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 357 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:48:00.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 95 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:48:00.000000Z\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/workspace/data_dst/%5d.png':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41avc1\n",
            "    encoder         : Lavf57.83.100\n",
            "    playback_requirements: QuickTime 6.0 or greater\n",
            "    playback_requirements-eng: QuickTime 6.0 or greater\n",
            "    Stream #0:0(eng): Video: png, rgb24, 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:48:00.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame= 1701 fps= 78 q=-0.0 Lsize=N/A time=00:01:08.04 bitrate=N/A speed=3.13x    \n",
            "video:373714kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFmPo0s2lTil",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33be6267-c1d6-41de-a021-f21f3e36ffab"
      },
      "source": [
        "#@title Denoise frames\n",
        "Data = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "Factor = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed denoise-image-sequence --input-dir workspace/\"+Data+\" --factor \"+str(Factor)\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "[7] Denoise factor? ( 1-20 ) : \n",
            "7\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '/content/workspace/data_dst/%6d.png':\n",
            "  Duration: 00:01:08.04, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 640x360 [SAR 1:1 DAR 16:9], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 (png) -> hqdn3d\n",
            "  hqdn3d -> Stream #0:0 (png)\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/workspace/data_dst/%6d.png':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: png, rgb24, 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame= 1701 fps= 58 q=-0.0 Lsize=N/A time=00:01:08.04 bitrate=N/A speed=2.33x    \n",
            "video:359728kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmq0Sj2bmq7d",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "335b3c1b-4313-47d8-a20b-7653cff9b559"
      },
      "source": [
        "#@title Detect faces\n",
        "Data = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "Detector = \"S3FD\" #@param [\"S3FD\", \"S3FD (whole face)\"]\n",
        "Debug = False #@param {type:\"boolean\"}\n",
        "\n",
        "detect_type = \"s3fd\"\n",
        "dbg = \" --output-debug\" if Debug else \" --no-output-debug\"\n",
        "\n",
        "folder = \"workspace/\"+Data\n",
        "folder_aligned = folder+\"/aligned\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py extract --input-dir \"+folder+\" --output-dir \"+folder_aligned\n",
        "cmd+=\" --detector \"+detect_type+\" --force-gpu-idxs 0\"+dbg\n",
        "\n",
        "if \"whole face\" in Detector:\n",
        "  cmd+=\" --face-type whole_face\" \n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "[wf] Face type ( f/wf/head ?:help ) : \n",
            "wf\n",
            "[0] Max number of faces from image ( ?:help ) : \n",
            "0\n",
            "[512] Image size ( 256-2048 ?:help ) : \n",
            "512\n",
            "[90] Jpeg quality ( 1-100 ?:help ) : \n",
            "90\n",
            "Extracting faces...\n",
            "Running on Tesla T4\n",
            "100% 1701/1701 [07:43<00:00,  3.67it/s]\n",
            "-------------------------\n",
            "Images found:        1701\n",
            "Faces detected:      1701\n",
            "-------------------------\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRNxUFE6p6Eu",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5451da44-62d6-443f-aff8-81fd20619ead"
      },
      "source": [
        "#@title Sort aligned\n",
        "Data = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "sort_type = \"hist\" #@param [\"blur\", \"face-yaw\", \"face-pitch\", \"face-source-rect-size\", \"hist\", \"hist-dissim\", \"brightness\", \"hue\", \"black\", \"origname\", \"oneface\", \"final\", \"final-faster\", \"absdiff\"]\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py sort --input-dir workspace/\"+Data+\"/aligned --by \"+sort_type\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Running sort tool.\n",
            "\n",
            "Sorting by histogram similarity...\n",
            "Running on 1 threads\n",
            "Sorting: 100% 1701/1701 [00:09<00:00, 188.09it/s]\n",
            "Renaming: 100% 1701/1701 [00:00<00:00, 26565.90it/s]\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5MbnVDyXkP7",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc43e45-474c-4945-f809-ce57f3c848ec"
      },
      "source": [
        "#@title Faceset Enhancer\n",
        "Data = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "data_path = \"/content/workspace/\"+Data+\"/aligned\"\n",
        "cmd = \"/content/DeepFaceLab/main.py facesettool enhance --input-dir \"+data_path\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Choose one or several GPU idxs (separated by comma).\n",
            "\n",
            "[CPU] : CPU\n",
            "  [0] : Tesla T4\n",
            "\n",
            "[0] Which GPU indexes to choose? : \n",
            "0\n",
            "\n",
            "Enhancing faceset in data_dst/aligned\n",
            "Processing to data_dst/aligned_enhanced\n",
            "Running on Tesla T4.\n",
            "100% 1701/1701 [55:52<00:00,  1.97s/it]\n",
            "[y] \n",
            "Merge data_dst/aligned_enhanced to data_dst/aligned ? ( y/n ) : y\n",
            "Copying processed files to data_dst/aligned\n",
            "Removing data_dst/aligned_enhanced\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VVvtoBMGnrA",
        "cellView": "form"
      },
      "source": [
        "#@title Apply or remove XSeg mask to the faces\n",
        "Mode = \"Remove mask\" #@param [\"Apply mask\", \"Remove mask\"]\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "main_path = \"/content/DeepFaceLab/main.py \"\n",
        "data_path = \"/content/workspace/\"+Data+\"/aligned \"\n",
        "mode_arg = \"apply \" if Mode == \"Apply mask\" else \"remove \"\n",
        "cmd = main_path+\"xseg \"+mode_arg+\"--input-dir \"+data_path\n",
        "cmd += \"--model-dir /content/workspace/model\" if mode_arg == \"apply \" else \"\"\n",
        "\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTuyUxgdLA13"
      },
      "source": [
        "## Train model\n",
        "\n",
        "* Choose your model type, but SAEHD is recommend for everyone\n",
        "* Set model options on output field\n",
        "* You can see preview manually, if go to model folder in filemanager and double click on preview.jpg file\n",
        "* Your workspace will be archived and upload to mounted Drive after 11 hours from start session\n",
        "* If you select \"Backup_every_hour\" option, your workspace will be backed up every hour.\n",
        "* Also, you can export your workspace manually in \"Manage workspace\" block\n",
        "* \"Silent_Start\" option provides to automatically start with best GPU and last used model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Kya-PJLDhv",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e5b3d9-da59-46e3-ab7e-7a74fb02cf22"
      },
      "source": [
        "#@title Training\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"Quick96\", \"XSeg\"]\n",
        "Backup_every_hour = True #@param {type:\"boolean\"}\n",
        "Silent_Start = True #@param {type:\"boolean\"}\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import psutil, os, time\n",
        "\n",
        "p = psutil.Process(os.getpid())\n",
        "uptime = time.time() - p.create_time()\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  if not os.path.exists('workspace.zip'):\n",
        "    print(\"Creating workspace archive ...\")\n",
        "    !zip -r -q workspace.zip workspace\n",
        "    print(\"Archive created!\")\n",
        "  else:\n",
        "    print(\"Archive exist!\")\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  print(\"Time to end session: \"+str(round((43200-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(3600)\n",
        "  backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -r -q workspace.zip workspace/model'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "elif (round(39600-uptime) > 0):\n",
        "  print(\"Time to backup: \"+str(round((39600-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(round(39600-uptime))\n",
        "  backup_cmd = \" --execute-program \"+backup_time+\" \\\"import os; os.system('zip -r -q workspace.zip workspace'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "else:\n",
        "  print(\"Session expires in less than an hour.\")\n",
        "  backup_cmd = \"\"\n",
        "    \n",
        "cmd = \"DeepFaceLab/main.py train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_dst/aligned --pretraining-data-dir pretrain --model-dir workspace/model --model \"+Model\n",
        "\n",
        "if Model == \"Quick96\":\n",
        "  cmd+= \" --pretrained-model-dir pretrain_Q96\"\n",
        "\n",
        "if Silent_Start:\n",
        "  cmd+= \" --silent-start\"\n",
        "\n",
        "if (backup_cmd != \"\"):\n",
        "  train_cmd = (cmd+backup_cmd)\n",
        "else:\n",
        "  train_cmd = (cmd)\n",
        "\n",
        "!python $train_cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Creating workspace archive ...\n",
            "Archive created!\n",
            "Time to end session: 9 hours\n",
            "Running trainer.\n",
            "\n",
            "[new] No saved models found. Enter a name of a new model : DFL\n",
            "DFL\n",
            "\n",
            "Model first run.\n",
            "Silent start: choosed device Tesla T4\n",
            "[0] Autobackup every N hour ( 0..24 ?:help ) : ?\n",
            "Autobackup model files with preview every N hour. Latest backup located in model/<>_autobackups/01\n",
            "[0] Autobackup every N hour ( 0..24 ?:help ) : 1\n",
            "1\n",
            "[n] Write preview history ( y/n ?:help ) : \n",
            "n\n",
            "[0] Target iteration : \n",
            "0\n",
            "[y] Flip faces randomly ( y/n ?:help ) : \n",
            "y\n",
            "[8] Batch_size ( ?:help ) : \n",
            "8\n",
            "[128] Resolution ( 64-640 ?:help ) : \n",
            "128\n",
            "[f] Face type ( h/mf/f/wf/head ?:help ) : \n",
            "f\n",
            "[liae-ud] AE architecture ( ?:help ) : \n",
            "liae-ud\n",
            "[256] AutoEncoder dimensions ( 32-1024 ?:help ) : \n",
            "256\n",
            "[64] Encoder dimensions ( 16-256 ?:help ) : \n",
            "64\n",
            "[64] Decoder dimensions ( 16-256 ?:help ) : \n",
            "64\n",
            "[22] Decoder mask dimensions ( 16-256 ?:help ) : \n",
            "22\n",
            "[n] Eyes and mouth priority ( y/n ?:help ) : \n",
            "n\n",
            "[n] Uniform yaw distribution of samples ( y/n ?:help ) : \n",
            "n\n",
            "[y] Place models and optimizer on GPU ( y/n ?:help ) : \n",
            "y\n",
            "[y] Use AdaBelief optimizer? ( y/n ?:help ) : \n",
            "y\n",
            "[n] Use learning rate dropout ( n/y/cpu ?:help ) : \n",
            "n\n",
            "[y] Enable random warp of samples ( y/n ?:help ) : \n",
            "y\n",
            "[0.0] GAN power ( 0.0 .. 1.0 ?:help ) : \n",
            "0.0\n",
            "[0.0] Face style power ( 0.0..100.0 ?:help ) : \n",
            "0.0\n",
            "[0.0] Background style power ( 0.0..100.0 ?:help ) : \n",
            "0.0\n",
            "[none] Color transfer for src faceset ( none/rct/lct/mkl/idt/sot ?:help ) : \n",
            "none\n",
            "[n] Enable gradient clipping ( y/n ?:help ) : \n",
            "n\n",
            "[n] Enable pretraining mode ( y/n ?:help ) : \n",
            "n\n",
            "Initializing models: 100% 5/5 [00:36<00:00,  7.30s/it]\n",
            "Loading samples: 100% 1109/1109 [00:16<00:00, 69.28it/s]\n",
            "Loading samples: 100% 1701/1701 [00:23<00:00, 72.41it/s]\n",
            "=========== Model Summary ============\n",
            "==                                  ==\n",
            "==            Model name: DFL_SAEHD ==\n",
            "==                                  ==\n",
            "==     Current iteration: 0         ==\n",
            "==                                  ==\n",
            "==--------- Model Options ----------==\n",
            "==                                  ==\n",
            "==            resolution: 128       ==\n",
            "==             face_type: f         ==\n",
            "==     models_opt_on_gpu: True      ==\n",
            "==                 archi: liae-ud   ==\n",
            "==               ae_dims: 256       ==\n",
            "==                e_dims: 64        ==\n",
            "==                d_dims: 64        ==\n",
            "==           d_mask_dims: 22        ==\n",
            "==       masked_training: True      ==\n",
            "==       eyes_mouth_prio: False     ==\n",
            "==           uniform_yaw: False     ==\n",
            "==             adabelief: True      ==\n",
            "==            lr_dropout: n         ==\n",
            "==           random_warp: True      ==\n",
            "==       true_face_power: 0.0       ==\n",
            "==      face_style_power: 0.0       ==\n",
            "==        bg_style_power: 0.0       ==\n",
            "==               ct_mode: none      ==\n",
            "==              clipgrad: False     ==\n",
            "==              pretrain: False     ==\n",
            "==       autobackup_hour: 1         ==\n",
            "== write_preview_history: False     ==\n",
            "==           target_iter: 0         ==\n",
            "==           random_flip: True      ==\n",
            "==            batch_size: 8         ==\n",
            "==             gan_power: 0.0       ==\n",
            "==        gan_patch_size: 16        ==\n",
            "==              gan_dims: 16        ==\n",
            "==                                  ==\n",
            "==----------- Running On -----------==\n",
            "==                                  ==\n",
            "==          Device index: 0         ==\n",
            "==                  Name: Tesla T4  ==\n",
            "==                  VRAM: 14.76GB   ==\n",
            "==                                  ==\n",
            "======================================\n",
            "Starting. Press \"Enter\" to stop training and save model.\n",
            "\n",
            "Trying to do the first iteration. If an error occurs, reduce the model parameters.\n",
            "\n",
            "You are training the model from scratch. It is strongly recommended to use a pretrained model to speed up the training and improve the quality.\n",
            "\n",
            "[19:34:46][#000002][0388ms][5.0211][4.9535]\n",
            "[19:49:41][#002061][0364ms][0.9919][0.8581]\n",
            "[20:04:41][#004211][0426ms][0.6208][0.4924]\n",
            "[20:19:42][#006368][0735ms][0.5268][0.4103]\n",
            "Backed up!\n",
            "[20:38:35][#008533][1456ms][0.4699][0.3640]\n",
            "[20:49:42][#010037][0471ms][0.4368][0.3382]\n",
            "[21:04:41][#012172][0375ms][0.4099][0.3196]\n",
            "[21:19:42][#014314][0385ms][0.3819][0.3009]\n",
            "[21:34:56][#016446][0363ms][0.3605][0.2873]\n",
            "[21:35:00][#016456][0404ms][0.3775][0.2403]Backed up!\n",
            "[21:49:42][#017681][0410ms][0.3458][0.2775]\n",
            "[22:04:42][#019704][0371ms][0.3327][0.2688]\n",
            "[22:19:42][#021738][0414ms][0.3177][0.2602]\n",
            "[22:34:57][#023836][0389ms][0.3072][0.2528]\n",
            "[22:35:01][#023839][2938ms][0.2751][0.2430]Backed up!\n",
            "[22:45:42][#024271][0349ms][0.3366][0.2450]\n",
            "[22:45:48][#024285][0357ms][0.2834][0.2646]\n",
            "[22:45:50][#024288][0696ms][0.3859][0.2925]\n",
            "[22:45:51][#024293][0388ms][0.3187][0.2197]\n",
            "\n",
            "[22:45:52][#024294][0466ms][0.2597][0.2306]\n",
            "\n",
            "[22:49:42][#024801][0395ms][0.2993][0.2472]\n",
            "[22:51:11][#025010][0403ms][0.2868][0.2242]\n",
            "[22:58:55][#026040][0417ms][0.2995][0.2433]Process Process-13:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeepFaceLab/mainscripts/Trainer.py\", line 353, in main\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/DeepFaceLab/models/ModelBase.py\", line 664, in process\n",
            "    time.sleep(0.01)\n",
            "KeyboardInterrupt\n",
            "    io.process_messages(0.1)\n",
            "  File \"/content/DeepFaceLab/core/interact/interact.py\", line 188, in process_messages\n",
            "    self.on_process_messages(sleep_time)\n",
            "  File \"/content/DeepFaceLab/core/interact/interact.py\", line 572, in on_process_messages\n",
            "    time.sleep(sleep_time)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"DeepFaceLab/main.py\", line 324, in <module>\n",
            "    arguments.func(arguments)\n",
            "  File \"DeepFaceLab/main.py\", line 132, in process_train\n",
            "    Trainer.main(**kwargs)\n",
            "  File \"/content/DeepFaceLab/mainscripts/Trainer.py\", line 353, in main\n",
            "    io.process_messages(0.1)\n",
            "KeyboardInterrupt\n",
            "[22:58:56][#026041][0413ms][0.3526][0.2199]Process Process-9:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleGeneratorFace.py\", line 134, in batch_func\n",
            "    x, = SampleProcessor.process ([sample], self.sample_process_options, self.output_sample_types, self.debug, ct_sample=ct_sample)\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleProcessor.py\", line 159, in process\n",
            "    mat = LandmarksProcessor.get_transform_mat (sample_landmarks, resolution, face_type)\n",
            "  File \"/content/DeepFaceLab/facelib/LandmarksProcessor.py\", line 284, in get_transform_mat\n",
            "    g_p = transform_points (  np.float32([(0,0),(1,0),(1,1),(0,1),(0.5,0.5) ]) , mat, True)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/DeepFaceLab/core/joblib/SubprocessGenerator.py\", line 54, in process_func\n",
            "    gen_data = next (self.generator_func)\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleGeneratorFace.py\", line 136, in batch_func\n",
            "    raise Exception (\"Exception occured in sample %s. Error: %s\" % (sample.filename, traceback.format_exc() ) )\n",
            "Exception: Exception occured in sample /content/workspace/data_src/aligned/00306.jpg. Error: Traceback (most recent call last):\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleGeneratorFace.py\", line 134, in batch_func\n",
            "    x, = SampleProcessor.process ([sample], self.sample_process_options, self.output_sample_types, self.debug, ct_sample=ct_sample)\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleProcessor.py\", line 159, in process\n",
            "    mat = LandmarksProcessor.get_transform_mat (sample_landmarks, resolution, face_type)\n",
            "  File \"/content/DeepFaceLab/facelib/LandmarksProcessor.py\", line 284, in get_transform_mat\n",
            "    g_p = transform_points (  np.float32([(0,0),(1,0),(1,1),(0,1),(0.5,0.5) ]) , mat, True)\n",
            "KeyboardInterrupt\n",
            "\n",
            "[22:58:56][#026042][0357ms][0.2862][0.2513]Process Process-12:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleGeneratorFace.py\", line 134, in batch_func\n",
            "    x, = SampleProcessor.process ([sample], self.sample_process_options, self.output_sample_types, self.debug, ct_sample=ct_sample)\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleProcessor.py\", line 165, in process\n",
            "    img = imagelib.warp_by_params (params_per_resolution[resolution], img, warp, transform, can_flip=True, border_replicate=border_replicate, cv2_inter=cv2.INTER_LINEAR)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/DeepFaceLab/core/joblib/SubprocessGenerator.py\", line 54, in process_func\n",
            "    gen_data = next (self.generator_func)\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleGeneratorFace.py\", line 136, in batch_func\n",
            "    raise Exception (\"Exception occured in sample %s. Error: %s\" % (sample.filename, traceback.format_exc() ) )\n",
            "Exception: Exception occured in sample /content/workspace/data_dst/aligned/00107.jpg. Error: Traceback (most recent call last):\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleGeneratorFace.py\", line 134, in batch_func\n",
            "    x, = SampleProcessor.process ([sample], self.sample_process_options, self.output_sample_types, self.debug, ct_sample=ct_sample)\n",
            "  File \"/content/DeepFaceLab/samplelib/SampleProcessor.py\", line 165, in process\n",
            "    img = imagelib.warp_by_params (params_per_resolution[resolution], img, warp, transform, can_flip=True, border_replicate=border_replicate, cv2_inter=cv2.INTER_LINEAR)\n",
            "KeyboardInterrupt\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
            "    util._exit_function()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
            "    _run_finalizers()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
            "    thread.join()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avAcSL_uvtq_"
      },
      "source": [
        "## Merge frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Y8K22Sv9Gn",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2348e162-8ecf-41d7-bea4-5595420fdb92"
      },
      "source": [
        "#@title Merge\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"Quick96\" ]\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py merge --input-dir workspace/data_dst --output-dir workspace/data_dst/merged --output-mask-dir workspace/data_dst/merged_mask --aligned-dir workspace/data_dst/aligned --model-dir workspace/model --model \"+Model\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Running merger.\n",
            "\n",
            "Choose one of saved models, or enter a name to create a new model.\n",
            "[r] : rename\n",
            "[d] : delete\n",
            "\n",
            "[0] : DFL - latest\n",
            " : \n",
            "0\n",
            "Loading DFL_SAEHD model...\n",
            "\n",
            "Choose one or several GPU idxs (separated by comma).\n",
            "\n",
            "[CPU] : CPU\n",
            "  [0] : Tesla T4\n",
            "\n",
            "[0] Which GPU indexes to choose? : \n",
            "0\n",
            "\n",
            "Initializing models: 100% 4/4 [00:09<00:00,  2.43s/it]\n",
            "=========== Model Summary ============\n",
            "==                                  ==\n",
            "==            Model name: DFL_SAEHD ==\n",
            "==                                  ==\n",
            "==     Current iteration: 24800     ==\n",
            "==                                  ==\n",
            "==--------- Model Options ----------==\n",
            "==                                  ==\n",
            "==            resolution: 128       ==\n",
            "==             face_type: f         ==\n",
            "==     models_opt_on_gpu: True      ==\n",
            "==                 archi: liae-ud   ==\n",
            "==               ae_dims: 256       ==\n",
            "==                e_dims: 64        ==\n",
            "==                d_dims: 64        ==\n",
            "==           d_mask_dims: 22        ==\n",
            "==       masked_training: True      ==\n",
            "==       eyes_mouth_prio: False     ==\n",
            "==           uniform_yaw: False     ==\n",
            "==             adabelief: True      ==\n",
            "==            lr_dropout: n         ==\n",
            "==           random_warp: True      ==\n",
            "==       true_face_power: 0.0       ==\n",
            "==      face_style_power: 0.0       ==\n",
            "==        bg_style_power: 0.0       ==\n",
            "==               ct_mode: none      ==\n",
            "==              clipgrad: False     ==\n",
            "==              pretrain: False     ==\n",
            "==       autobackup_hour: 1         ==\n",
            "== write_preview_history: False     ==\n",
            "==           target_iter: 0         ==\n",
            "==           random_flip: True      ==\n",
            "==            batch_size: 8         ==\n",
            "==             gan_power: 0.0       ==\n",
            "==        gan_patch_size: 16        ==\n",
            "==              gan_dims: 16        ==\n",
            "==                                  ==\n",
            "==----------- Running On -----------==\n",
            "==                                  ==\n",
            "==          Device index: 0         ==\n",
            "==                  Name: Tesla T4  ==\n",
            "==                  VRAM: 14.76GB   ==\n",
            "==                                  ==\n",
            "======================================\n",
            "Choose mode: \n",
            "(0) original\n",
            "(1) overlay\n",
            "(2) hist-match\n",
            "(3) seamless\n",
            "(4) seamless-hist-match\n",
            "(5) raw-rgb\n",
            "(6) raw-predict\n",
            "\n",
            "[1] : 3\n",
            "3\n",
            "Choose mask mode: \n",
            "(1) dst\n",
            "(2) learned-prd\n",
            "(3) learned-dst\n",
            "(4) learned-prd*learned-dst\n",
            "(5) learned-prd+learned-dst\n",
            "(6) XSeg-prd\n",
            "(7) XSeg-dst\n",
            "(8) XSeg-prd*XSeg-dst\n",
            "(9) learned-prd*learned-dst*XSeg-prd*XSeg-dst\n",
            "\n",
            "[1] : \n",
            "1\n",
            "[0] Choose erode mask modifier ( -400..400 ) : \n",
            "0\n",
            "[0] Choose blur mask modifier ( 0..400 ) : \n",
            "0\n",
            "[0] Choose motion blur power ( 0..100 ) : \n",
            "0\n",
            "[0] Choose output face scale modifier ( -50..50 ) : \n",
            "0\n",
            "Color transfer to predicted face ( rct/lct/mkl/mkl-m/idt/idt-m/sot-m/mix-m ) : \n",
            "\n",
            "Choose sharpen mode: \n",
            "(0) None\n",
            "(1) box\n",
            "(2) gaussian\n",
            "\n",
            "[0] ( ?:help ) : 2\n",
            "2\n",
            "[0] Choose blur/sharpen amount ( -100..100 ) : \n",
            "0\n",
            "[0] Choose super resolution power ( 0..100 ?:help ) : 20\n",
            "20\n",
            "[0] Choose image degrade by denoise power ( 0..500 ) : \n",
            "0\n",
            "[0] Choose image degrade by bicubic rescale power ( 0..100 ) : \n",
            "0\n",
            "[0] Degrade color power of final image ( 0..100 ) : \n",
            "0\n",
            "\n",
            "[8] Number of workers? ( 1-2 ?:help ) : \n",
            "8\n",
            "Collecting alignments: 100% 1701/1701 [00:25<00:00, 67.24it/s]\n",
            "Computing motion vectors: 100% 1701/1701 [00:02<00:00, 800.06it/s]\n",
            "Running on CPU1.\n",
            "Running on CPU5.\n",
            "Running on CPU2.\n",
            "Running on CPU7.\n",
            "Running on CPU0.\n",
            "Running on CPU6.\n",
            "Running on CPU3.\n",
            "Running on CPU4.\n",
            "Merging: 100% 1701/1701 [04:16<00:00,  6.63it/s]\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNeGfiZpxlnz",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70e4ae3-3790-43be-b3c3-00cdded4a5a8"
      },
      "source": [
        "#@title Get result video \n",
        "Mode = \"result video\" #@param [\"result video\", \"result_mask video\"]\n",
        "Copy_to_Drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Mode == \"result video\":\n",
        "  !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged --output-file workspace/result.mp4 --reference-file workspace/data_dst.mp4 --include-audio\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged_mask --output-file workspace/result_mask.mp4 --reference-file workspace/data_dst.mp4\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[16] Bitrate of output file in MB/s : \n",
            "16\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2pipe, from 'pipe:':\n",
            "  Duration: N/A, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 640x360, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/content/workspace/data_dst.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41avc1\n",
            "    creation_time   : 2021-02-02T17:48:00.000000Z\n",
            "    playback_requirements: QuickTime 6.0 or greater\n",
            "    playback_requirements-eng: QuickTime 6.0 or greater\n",
            "    encoder         : vlc 3.0.8 stream output\n",
            "    encoder-eng     : vlc 3.0.8 stream output\n",
            "  Duration: 00:01:08.04, start: 0.000000, bitrate: 458 kb/s\n",
            "    Stream #1:0(eng): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 357 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:48:00.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #1:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 95 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:48:00.000000Z\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "  Stream #1:1 -> #0:1 (aac (native) -> aac (native))\n",
            "\u001b[0;35m[image2pipe @ 0x55bce21b4000] \u001b[0m\u001b[0;33mThread message queue blocking; consider raising the thread_queue_size option (current value: 8)\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mprofile High, level 4.1\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=abr mbtree=1 bitrate=16000 ratetol=1.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/workspace/result.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 640x360, q=-1--1, 16000 kb/s, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/16000000 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 192 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:48:00.000000Z\n",
            "      handler_name    : SoundHandler\n",
            "      encoder         : Lavc57.107.100 aac\n",
            "frame= 1701 fps= 53 q=-1.0 Lsize=   39332kB time=00:01:08.00 bitrate=4738.0kbits/s speed=2.12x    \n",
            "video:37659kB audio:1623kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.129424%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mframe I:7     Avg QP: 0.04  size: 97802\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mframe P:686   Avg QP: 0.04  size: 36068\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mframe B:1008  Avg QP: 2.15  size: 13031\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mconsecutive B-frames: 15.6% 12.3% 11.1% 60.9%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mmb I  I16..4: 27.9% 17.8% 54.3%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mmb P  I16..4:  1.7%  0.6%  0.9%  P16..4: 37.7% 11.0% 12.0%  0.0%  0.0%    skip:36.1%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mmb B  I16..4:  0.1%  0.0%  0.0%  B16..8: 28.3%  6.9%  6.6%  direct: 9.0%  skip:49.1%  L0:46.2% L1:46.2% BI: 7.5%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mfinal ratefactor: -16.27\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0m8x8 transform intra:18.8% inter:26.5%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mcoded y,uvDC,uvAC intra: 61.6% 75.6% 74.1% inter: 31.3% 38.1% 38.0%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mi16 v,h,dc,p: 49% 42%  6%  3%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 26% 29%  1%  4%  4%  4%  3%  3%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 33% 24% 11%  4%  6%  7%  5%  5%  5%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mi8c dc,h,v,p: 43% 32% 20%  5%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mref P L0: 88.0%  3.6%  5.6%  2.8%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mref B L0: 95.9%  3.1%  1.0%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mref B L1: 99.4%  0.6%\n",
            "\u001b[1;36m[libx264 @ 0x55bce2a52000] \u001b[0mkb/s:4534.02\n",
            "\u001b[1;36m[aac @ 0x55bce2a52f00] \u001b[0mQavg: 1466.202\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}